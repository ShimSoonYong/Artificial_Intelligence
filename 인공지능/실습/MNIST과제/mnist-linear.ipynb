{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch import optim\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Current Device: {device}')\n\ntransform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = datasets.MNIST(root='./data', train=True, download=True,\n                               transform=transform)\ntest_dataset = datasets.MNIST(root='./data', train=False, download=True,\n                              transform=transform)\n\nprint(f'훈련 데이터의 차원: {train_dataset.data.shape}')\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n\n# DataLoader의 첫 번째 배치 출력\nfirst_batch = next(iter(train_loader))\nprint(type(first_batch))\nprint(len(first_batch))\n\n# 훈련 루프\nfor epochs in range(10, 40, 5):\n    NN_model = nn.Sequential(\n    nn.Linear(in_features=28*28, out_features=256),\n    nn.ReLU(),\n    nn.Linear(in_features=256, out_features=128),\n    nn.ReLU(),\n    nn.Linear(in_features=128, out_features=64),\n    nn.ReLU(),\n    nn.Linear(in_features=64, out_features=10)\n    ).to(device)\n\n    # 손실함수와 최적화 기법 정의\n    loss_fn = nn.CrossEntropyLoss().to(device)\n    optimizer = optim.SGD(NN_model.parameters(), lr=0.01)\n\n    for epoch in range(epochs):\n        NN_model.train()\n\n        for i, (X, y) in enumerate(train_loader):\n            running_loss = 0\n            optimizer.zero_grad()\n\n            X = X.view(-1, 28*28).to(device)\n\n            hypothesis = NN_model(X)\n            loss = loss_fn(hypothesis, y.to(device))\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n    print(f\"Training Finished for {(epochs-5)//5} experiment.\")\n\n    # 평가 루프\n    with torch.no_grad():\n        correct_per_class = torch.zeros(10)\n        total_per_class = torch.zeros(10)\n\n        for X, y in test_loader:\n            NN_model.eval()\n\n            X = X.view(-1, 28*28).to(device)\n\n            hypothesis = NN_model(X)\n\n            predicted = torch.argmax(hypothesis, dim=1)\n\n            true_labels = y\n\n            for i in range(10):\n                class_mask = (true_labels == i)\n\n                # 맞춘 개수\n                correct_per_class[i] += (predicted[class_mask] == i).sum().item()\n\n                # 전체 개수\n                total_per_class[i] += class_mask.sum().item()\n\n    # 각 클래스에 대한 정확도 출력\n    for i in range(10):\n        if total_per_class[i] > 0:  # 해당 클래스에 대한 샘플이 있을 경우\n            accuracy = correct_per_class[i] / total_per_class[i]\n            print(f'Accuracy for class {i}: {accuracy * 100:.2f}%')\n        else:\n            print(f'No samples for class {i}')\n            \n    accuracy = correct_per_class / total_per_class\n    # 가장 정확도가 높은 클래스 출력\n    acc, label = torch.max(accuracy, dim=0)\n    print(f'Max Accuracy: {acc}| The Class: {label}')\n\n    # 가장 정확도가 낮은 클래스 출력\n    acc, label = torch.min(accuracy, dim=0)\n    print(f'Min Accuracy: {acc}| The Class: {label}')\n\n    # 전체 정확도 출력\n    acc = torch.mean(accuracy, dim=0)\n    print(f'Total Accuracy: {acc}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-23T10:19:44.042758Z","iopub.execute_input":"2024-09-23T10:19:44.043146Z","iopub.status.idle":"2024-09-23T10:47:36.948753Z","shell.execute_reply.started":"2024-09-23T10:19:44.043105Z","shell.execute_reply":"2024-09-23T10:47:36.947655Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Current Device: cuda\n훈련 데이터의 차원: torch.Size([60000, 28, 28])\n<class 'list'>\n2\nTraining Finished for 1 experiment.\nAccuracy for class 0: 98.67%\nAccuracy for class 1: 99.03%\nAccuracy for class 2: 96.80%\nAccuracy for class 3: 97.33%\nAccuracy for class 4: 98.68%\nAccuracy for class 5: 96.97%\nAccuracy for class 6: 97.81%\nAccuracy for class 7: 95.91%\nAccuracy for class 8: 97.13%\nAccuracy for class 9: 95.94%\nMax Accuracy: 0.9903083443641663| The Class: 1\nMin Accuracy: 0.9591439962387085| The Class: 7\nTotal Accuracy: 0.9742667078971863\nTraining Finished for 2 experiment.\nAccuracy for class 0: 98.27%\nAccuracy for class 1: 99.30%\nAccuracy for class 2: 97.87%\nAccuracy for class 3: 97.52%\nAccuracy for class 4: 99.08%\nAccuracy for class 5: 97.31%\nAccuracy for class 6: 98.02%\nAccuracy for class 7: 98.15%\nAccuracy for class 8: 96.82%\nAccuracy for class 9: 95.94%\nMax Accuracy: 0.992951512336731| The Class: 1\nMin Accuracy: 0.959365725517273| The Class: 9\nTotal Accuracy: 0.9782686233520508\nTraining Finished for 3 experiment.\nAccuracy for class 0: 98.78%\nAccuracy for class 1: 99.03%\nAccuracy for class 2: 98.35%\nAccuracy for class 3: 98.42%\nAccuracy for class 4: 97.86%\nAccuracy for class 5: 97.09%\nAccuracy for class 6: 98.02%\nAccuracy for class 7: 96.98%\nAccuracy for class 8: 97.84%\nAccuracy for class 9: 97.52%\nMax Accuracy: 0.9903083443641663| The Class: 1\nMin Accuracy: 0.9698443412780762| The Class: 7\nTotal Accuracy: 0.979888916015625\nTraining Finished for 4 experiment.\nAccuracy for class 0: 98.67%\nAccuracy for class 1: 99.30%\nAccuracy for class 2: 97.58%\nAccuracy for class 3: 98.12%\nAccuracy for class 4: 97.86%\nAccuracy for class 5: 97.42%\nAccuracy for class 6: 98.23%\nAccuracy for class 7: 97.18%\nAccuracy for class 8: 97.43%\nAccuracy for class 9: 96.63%\nMax Accuracy: 0.992951512336731| The Class: 1\nMin Accuracy: 0.966303288936615| The Class: 9\nTotal Accuracy: 0.9784161448478699\nTraining Finished for 5 experiment.\nAccuracy for class 0: 99.18%\nAccuracy for class 1: 98.94%\nAccuracy for class 2: 97.38%\nAccuracy for class 3: 98.02%\nAccuracy for class 4: 97.76%\nAccuracy for class 5: 97.98%\nAccuracy for class 6: 97.70%\nAccuracy for class 7: 97.57%\nAccuracy for class 8: 97.33%\nAccuracy for class 9: 97.82%\nMax Accuracy: 0.9918367266654968| The Class: 0\nMin Accuracy: 0.9733059406280518| The Class: 8\nTotal Accuracy: 0.9796935319900513\nTraining Finished for 6 experiment.\nAccuracy for class 0: 98.88%\nAccuracy for class 1: 99.03%\nAccuracy for class 2: 97.97%\nAccuracy for class 3: 97.92%\nAccuracy for class 4: 98.17%\nAccuracy for class 5: 97.31%\nAccuracy for class 6: 98.12%\nAccuracy for class 7: 97.57%\nAccuracy for class 8: 97.13%\nAccuracy for class 9: 98.32%\nMax Accuracy: 0.9903083443641663| The Class: 1\nMin Accuracy: 0.9712525606155396| The Class: 8\nTotal Accuracy: 0.9804002642631531\n","output_type":"stream"}]}]}