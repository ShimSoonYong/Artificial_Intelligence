{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D convolution layer.\n",
      "\n",
      "    This layer creates a convolution kernel that is convolved with the layer\n",
      "    input over a 2D spatial (or temporal) dimension (height and width) to\n",
      "    produce a tensor of outputs. If `use_bias` is True, a bias vector is created\n",
      "    and added to the outputs. Finally, if `activation` is not `None`, it is\n",
      "    applied to the outputs as well.\n",
      "\n",
      "    Args:\n",
      "        filters: int, the dimension of the output space (the number of filters\n",
      "            in the convolution).\n",
      "        kernel_size: int or tuple/list of 2 integer, specifying the size of the\n",
      "            convolution window.\n",
      "        strides: int or tuple/list of 2 integer, specifying the stride length\n",
      "            of the convolution. `strides > 1` is incompatible with\n",
      "            `dilation_rate > 1`.\n",
      "        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n",
      "            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n",
      "            the left/right or up/down of the input. When `padding=\"same\"` and\n",
      "            `strides=1`, the output has the same size as the input.\n",
      "        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n",
      "            The ordering of the dimensions in the inputs. `\"channels_last\"`\n",
      "            corresponds to inputs with shape\n",
      "            `(batch_size, height, width, channels)`\n",
      "            while `\"channels_first\"` corresponds to inputs with shape\n",
      "            `(batch_size, channels, height, width)`. It defaults to the\n",
      "            `image_data_format` value found in your Keras config file at\n",
      "            `~/.keras/keras.json`. If you never set it, then it will be\n",
      "            `\"channels_last\"`.\n",
      "        dilation_rate: int or tuple/list of 2 integers, specifying the dilation\n",
      "            rate to use for dilated convolution.\n",
      "        groups: A positive int specifying the number of groups in which the\n",
      "            input is split along the channel axis. Each group is convolved\n",
      "            separately with `filters // groups` filters. The output is the\n",
      "            concatenation of all the `groups` results along the channel axis.\n",
      "            Input channels and `filters` must both be divisible by `groups`.\n",
      "        activation: Activation function. If `None`, no activation is applied.\n",
      "        use_bias: bool, if `True`, bias will be added to the output.\n",
      "        kernel_initializer: Initializer for the convolution kernel. If `None`,\n",
      "            the default initializer (`\"glorot_uniform\"`) will be used.\n",
      "        bias_initializer: Initializer for the bias vector. If `None`, the\n",
      "            default initializer (`\"zeros\"`) will be used.\n",
      "        kernel_regularizer: Optional regularizer for the convolution kernel.\n",
      "        bias_regularizer: Optional regularizer for the bias vector.\n",
      "        activity_regularizer: Optional regularizer function for the output.\n",
      "        kernel_constraint: Optional projection function to be applied to the\n",
      "            kernel after being updated by an `Optimizer` (e.g. used to implement\n",
      "            norm constraints or value constraints for layer weights). The\n",
      "            function must take as input the unprojected variable and must return\n",
      "            the projected variable (which must have the same shape). Constraints\n",
      "            are not safe to use when doing asynchronous distributed training.\n",
      "        bias_constraint: Optional projection function to be applied to the\n",
      "            bias after being updated by an `Optimizer`.\n",
      "\n",
      "    Input shape:\n",
      "\n",
      "    - If `data_format=\"channels_last\"`:\n",
      "        A 4D tensor with shape: `(batch_size, height, width, channels)`\n",
      "    - If `data_format=\"channels_first\"`:\n",
      "        A 4D tensor with shape: `(batch_size, channels, height, width)`\n",
      "\n",
      "    Output shape:\n",
      "\n",
      "    - If `data_format=\"channels_last\"`:\n",
      "        A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n",
      "    - If `data_format=\"channels_first\"`:\n",
      "        A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`\n",
      "\n",
      "    Returns:\n",
      "        A 4D tensor representing `activation(conv2d(inputs, kernel) + bias)`.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
      "\n",
      "    Example:\n",
      "\n",
      "    >>> x = np.random.rand(4, 10, 10, 128)\n",
      "    >>> y = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
      "    >>> print(y.shape)\n",
      "    (4, 8, 8, 32)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.keras.layers.Conv2D.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) 기본 개념\n",
    "\n",
    "## CNN의 소개\n",
    "- Convolutional Neural Networks (CNN) 는 합성곱 연산을 사용하는 특수한 종류의 신경망입니다.\n",
    "- CNN은 이미지 처리와 컴퓨터 비전 분야에서 널리 사용되며, 기본적으로 특징 추출을 위해 합성곱을 사용합니다.\n",
    "\n",
    "### 1차원에서의 합성곱 연산\n",
    "- 1차원 신호의 합성곱 연산은 신호와 가중치 함수(필터) 의 곱셈을 통해 이루어집니다.\n",
    "- 수식:\n",
    "  \n",
    "$$\n",
    "  s'(t) = \\int s(u) \\cdot w(u - t) du\n",
    "$$\n",
    "\n",
    "### 2차원에서의 합성곱 연산\n",
    "- 2차원 합성곱은 일반적으로 이미지 에 적용되며, 가중치 행렬(필터)과 이미지의 특정 영역이 곱해져서 출력됩니다.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# 입력 이미지 텐서 (배치 크기: 10, 높이: 28, 너비: 28, 채널: 1)\n",
    "input_image = tf.random.normal(shape=(10, 28, 28, 1))\n",
    "\n",
    "# 필터 (커널) 생성\n",
    "filter = tf.eye(3)  # 3x3 필터\n",
    "filter = tf.reshape(filter, (3, 3, 1, 1))\n",
    "\n",
    "# 2D 합성곱 연산\n",
    "output = tf.nn.conv2d(input_image, filters=filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "print(output)\n",
    "```\n",
    "\n",
    "- `tf.nn.conv2d`는 2D 합성곱을 수행하며, 입력 텐서와 필터의 차원은 4차원으로 주어져야 합니다.\n",
    "\n",
    "## CNN 아키텍처의 기본 구성\n",
    "- CNN은 주로 다음과 같은 세 가지 계층으로 구성됩니다:\n",
    "  1. 합성곱 계층 (Convolutional Layer)\n",
    "  2. 풀링 계층 (Pooling Layer)\n",
    "  3. 완전 연결 계층 (Fully Connected Layer)\n",
    "\n",
    "### 합성곱 계층\n",
    "- 합성곱 계층은 필터를 사용하여 입력 데이터의 중요한 특징을 추출합니다.\n",
    "- 필터의 크기, 패딩, 스트라이드 등의 하이퍼파라미터에 따라 출력 크기가 결정됩니다.\n",
    "\n",
    "### 풀링 계층\n",
    "- 풀링 계층은 입력 데이터를 줄이기 위해 사용되며, 주로 최대 풀링과 평균 풀링을 사용합니다.\n",
    "- 풀링 계층은 과적합 방지 및 계산 효율성을 높이기 위해 사용됩니다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 연산에 따른 차원 변환 규칙 (Convolution Dimension Calculation)\n",
    "\n",
    "합성곱 연산(Convolution)을 수행할 때, 출력 텐서의 크기는 입력 크기, 필터 크기, 스트라이드(stride), 그리고 패딩(padding)에 따라 결정됩니다. 아래는 이 차원 변환의 규칙을 설명합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. 차원 변환 공식 (2D 합성곱 기준)\n",
    "\n",
    "출력 크기는 다음 공식을 사용해 계산됩니다:\n",
    "\n",
    "$$\n",
    "\\text{Output Height (or Width)} = \\frac{(\\text{Input Size} - \\text{Filter Size} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "$$\n",
    "\n",
    "- Input Size: 입력 텐서의 크기 (높이 또는 너비)\n",
    "- Filter Size: 필터의 크기 (커널 크기, 예: 3x3 필터는 크기가 3)\n",
    "- Padding: 패딩의 양 (입력 텐서 주변에 추가된 제로 패딩)\n",
    "- Stride: 필터가 한 번에 이동하는 픽셀 수\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 패딩(Padding)\n",
    "패딩은 입력 텐서의 크기를 유지하거나 줄이는 역할을 합니다.\n",
    "\n",
    "1. Valid Padding (패딩 없음):\n",
    "   - 패딩을 추가하지 않는 방식. 입력 텐서의 크기가 줄어듭니다.\n",
    "   - 패딩 크기 `P = 0`으로 설정됩니다.\n",
    "   - 공식:\n",
    "     $$\n",
    "     \\text{Output Size} = \\frac{(\\text{Input Size} - \\text{Filter Size})}{\\text{Stride}} + 1\n",
    "     $$\n",
    "   \n",
    "   - 예시:\n",
    "     - 입력 크기: 5x5\n",
    "     - 필터 크기: 3x3\n",
    "     - 스트라이드: 1\n",
    "     - 패딩: 없음 (valid)\n",
    "     - 출력 크기:\n",
    "       $$\n",
    "       \\frac{(5 - 3)}{1} + 1 = 3\n",
    "       $$\n",
    "     - 결과: 3x3 출력\n",
    "\n",
    "2. Same Padding (출력 크기를 입력과 동일하게 유지):\n",
    "   - 출력 텐서의 크기를 입력과 동일하게 유지하기 위해 입력에 제로 패딩을 추가합니다.\n",
    "   - 패딩 크기 `P`는 필터 크기와 스트라이드에 따라 계산됩니다.\n",
    "   - 공식:\n",
    "     $$\n",
    "     P = \\left\\lfloor \\frac{F - 1}{2} \\right\\rfloor\n",
    "     $$\n",
    "   - 예시:\n",
    "     - 입력 크기: 5x5\n",
    "     - 필터 크기: 3x3\n",
    "     - 스트라이드: 1\n",
    "     - 패딩: same\n",
    "     - 출력 크기:\n",
    "       $$\n",
    "       \\frac{(5 - 3 + 2 \\times 1)}{1} + 1 = 5\n",
    "       $$\n",
    "     - 결과: 5x5 출력\n",
    "\n",
    "---\n",
    "\n",
    "### 3. 스트라이드(Stride)\n",
    "스트라이드는 필터가 한 번에 이동하는 픽셀 수입니다. 스트라이드가 클수록 출력 크기가 작아집니다.\n",
    "\n",
    "- Stride 1: 필터가 한 번에 1픽셀씩 이동 (출력 크기가 거의 줄지 않음).\n",
    "- Stride 2: 필터가 한 번에 2픽셀씩 이동 (출력 크기가 줄어듦).\n",
    "\n",
    "예시:\n",
    "- 입력 크기: 5x5\n",
    "- 필터 크기: 3x3\n",
    "- 스트라이드: 2\n",
    "- 패딩: 없음\n",
    "- 출력 크기:\n",
    "  $$\n",
    "  \\frac{(5 - 3)}{2} + 1 = 2\n",
    "  $$\n",
    "- 결과: 2x2 출력\n",
    "\n",
    "---\n",
    "\n",
    "### 4. 채널과 배치(batch size)\n",
    "- 채널 수는 입력 텐서와 필터의 세 번째 차원으로, 보통 이미지의 색상 채널(RGB)을 나타냅니다.\n",
    "- 배치 크기(batch size)는 입력 데이터의 개수로, 전체 텐서에서 첫 번째 차원으로 나타납니다.\n",
    "\n",
    "출력 텐서의 크기는 다음과 같은 4차원 텐서로 표현됩니다:\n",
    "- (Batch size, Output Height, Output Width, Output Channels)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. 3D 합성곱 (Conv3D)\n",
    "3D 합성곱에서는 3차원 입력 데이터를 처리하며, 차원 변환 규칙은 다음과 같습니다:\n",
    "\n",
    "$$\n",
    "\\text{Output Size} = \\frac{(\\text{Input Size} - \\text{Filter Size} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "$$\n",
    "\n",
    "이 공식은 3차원 공간(높이, 너비, 깊이)에 적용됩니다. 3D 합성곱은 주로 비디오 처리나 의료 영상 분석에 사용됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. 예시: 2D 합성곱 연산 계산\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# 입력 텐서 (배치 크기: 1, 높이: 5, 너비: 5, 채널: 1)\n",
    "input_tensor = tf.random.normal(shape=(1, 5, 5, 1))\n",
    "\n",
    "# 필터 (커널 크기: 3x3, 입력 채널: 1, 출력 채널: 1)\n",
    "filter_tensor = tf.random.normal(shape=(3, 3, 1, 1))\n",
    "\n",
    "# 2D 합성곱\n",
    "output_tensor = tf.nn.conv2d(input_tensor, filter_tensor, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "print(output_tensor.shape)\n",
    "```\n",
    "\n",
    "- 입력 크기: (5x5)\n",
    "- 필터 크기: 3x3\n",
    "- 스트라이드: 1\n",
    "- 패딩: VALID (패딩 없음)\n",
    "- 결과 출력 크기: (3x3)\n",
    "\n",
    "---\n",
    "\n",
    "### 7. 차원 변환 요약\n",
    "- 패딩: `same` 패딩은 입력 크기를 유지하고, `valid` 패딩은 크기를 줄입니다.\n",
    "- 스트라이드: 스트라이드가 클수록 출력 크기가 작아집니다.\n",
    "- 필터 크기: 필터 크기가 클수록 출력 크기가 줄어듭니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 참고: 합성곱 차원 계산 공식의 적용\n",
    "1. 2D 합성곱:\n",
    "   $$\n",
    "   \\text{Output Height} = \\frac{(\\text{Input Height} - \\text{Filter Height} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "   $$\n",
    "   $$\n",
    "   \\text{Output Width} = \\frac{(\\text{Input Width} - \\text{Filter Width} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "   $$\n",
    "\n",
    "2. 3D 합성곱:\n",
    "   $$\n",
    "   \\text{Output Depth} = \\frac{(\\text{Input Depth} - \\text{Filter Depth} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "   $$\n",
    "   $$\n",
    "   \\text{Output Height} = \\frac{(\\text{Input Height} - \\text{Filter Height} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "   $$\n",
    "   $$\n",
    "   \\text{Output Width} = \\frac{(\\text{Input Width} - \\text{Filter Width} + 2 \\times \\text{Padding})}{\\text{Stride}} + 1\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolutional Neural Network)에서 **커널 필터(kernel filter)** 는 이미지나 입력 데이터에서 **특징(feature)** 을 추출하는 중요한 역할을 담당합니다. CNN에서 커널 필터는 입력 데이터에 대해 **컨볼루션 연산(convolution operation)** 을 수행하여 공간적인 패턴(예: 엣지, 텍스처, 모양 등)을 감지합니다.\n",
    "\n",
    "### 커널 필터의 역할\n",
    "\n",
    "1. **특징 추출 (Feature Extraction)**\n",
    "   - 커널 필터는 이미지나 데이터의 특정 패턴(엣지, 선, 색상 변화 등)을 감지합니다. 예를 들어, 초기 층에서는 단순한 엣지나 방향성을 감지하는 필터가 사용될 수 있고, 네트워크가 깊어질수록 복잡한 고차원적인 패턴을 감지하는 필터가 사용됩니다.\n",
    "   \n",
    "2. **공간 관계 탐지 (Spatial Relationship Detection)**\n",
    "   - 커널 필터는 **로컬** 영역에서 입력 값의 상관관계를 학습합니다. 이는 이미지나 데이터 내에서 특정 위치의 픽셀들이 다른 위치의 픽셀들과 어떻게 상호작용하는지 학습하는 과정입니다.\n",
    "\n",
    "3. **파라미터 공유 (Parameter Sharing)**\n",
    "   - 커널 필터는 이미지의 각 위치에 동일한 필터를 적용하여 계산을 수행합니다. 이를 통해 이미지의 어느 위치에서도 동일한 특징을 감지할 수 있습니다. 이로 인해 **파라미터의 수를 크게 줄일 수 있으며**, 연산 효율성을 높일 수 있습니다.\n",
    "\n",
    "4. **차원 축소 (Dimensionality Reduction)**\n",
    "   - 커널 필터가 입력 데이터에 적용되면, 출력은 입력보다 작은 크기의 특징 맵(feature map)을 형성합니다. 이 과정을 통해 차원 축소가 일어나며, 이는 학습에 필요한 계산 비용을 줄이고, 중요한 특징만을 남기게 됩니다.\n",
    "\n",
    "5. **다중 필터 적용 (Multiple Filter Application)**\n",
    "   - CNN에서는 여러 개의 커널 필터를 사용하여 하나의 입력에 대해 다양한 특징 맵을 생성합니다. 예를 들어, 이미지의 세부적인 엣지 정보나 더 추상적인 패턴을 감지하기 위해 다양한 필터를 사용합니다. 이때 각 필터는 다른 종류의 특징을 학습하게 됩니다.\n",
    "\n",
    "### 커널 필터의 동작 과정\n",
    "\n",
    "1. **커널 필터 정의**\n",
    "   - 커널 필터는 일반적으로 2D 배열(행렬)로 나타나며, 작은 크기(예: 3x3, 5x5)를 가집니다. 이 필터는 입력 이미지의 부분 영역에 대해 **곱셈과 합산(Convolution)** 을 수행합니다.\n",
    "\n",
    "2. **슬라이딩 윈도우 방식**\n",
    "   - 커널 필터는 입력 이미지의 좌상단부터 시작하여 정해진 **스트라이드(stride)** 값만큼 이동하면서 연산을 수행합니다. 각 위치에서의 연산 결과는 하나의 출력 픽셀 값을 생성하며, 이 과정이 반복됩니다.\n",
    "\n",
    "3. **결과 출력 (Feature Map)**\n",
    "   - 필터가 입력 이미지에 대해 컨볼루션을 수행한 결과는 새로운 특징 맵을 생성합니다. 이 특징 맵은 입력 이미지의 특성을 반영한 값들로 구성되며, 다음 층으로 전달되어 더 고차원적인 특징을 학습하게 됩니다.\n",
    "\n",
    "### 커널 필터의 예시\n",
    "다음은 3x3 커널 필터가 어떻게 동작하는지에 대한 간단한 예입니다.\n",
    "\n",
    "#### 입력 이미지 (5x5):\n",
    "```\n",
    "1  1  1  0  0\n",
    "0  1  1  1  0\n",
    "0  0  1  1  1\n",
    "0  0  1  1  0\n",
    "0  1  1  0  0\n",
    "```\n",
    "\n",
    "#### 커널 필터 (3x3):\n",
    "```\n",
    "1  0 -1\n",
    "1  0 -1\n",
    "1  0 -1\n",
    "```\n",
    "\n",
    "#### 결과 특징 맵 (3x3):\n",
    "```\n",
    "2  1 -2\n",
    "1  0 -1\n",
    "-1 -1 -2\n",
    "```\n",
    "\n",
    "이 예시에서 3x3 커널 필터는 입력 이미지에 대해 특정 패턴(수직 엣지)을 감지하도록 설계되었습니다. 컨볼루션 연산을 통해 이 필터는 이미지의 수직 방향에서 강한 엣지를 감지한 결과를 출력합니다.\n",
    "\n",
    "### 요약\n",
    "- **커널 필터** 는 CNN에서 입력 데이터의 **특정 특징을 추출** 하는 중요한 요소입니다.\n",
    "- **컨볼루션 연산** 을 통해 입력 데이터에서 **로컬 패턴** 을 학습하고, 각 필터는 서로 다른 종류의 특징을 학습하게 됩니다.\n",
    "- 여러 커널 필터가 적용되어 **다양한 특징 맵** 을 생성하며, 이는 네트워크의 다음 층으로 전달되어 더 고차원적인 패턴을 학습하게 됩니다.\n",
    "\n",
    "CNN에서 커널 필터는 네트워크가 이미지에서 추상적이고 유용한 패턴을 인식할 수 있도록 도와주는 핵심 메커니즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolutional Neural Network)에서 활성화 함수는 각 층의 출력을 비선형성으로 변환하여 복잡한 패턴을 학습할 수 있도록 도와줍니다. 일반적으로 ReLU(Rectified Linear Unit)가 많이 사용됩니다.\n",
    "\n",
    "### CNN에서 활성화 함수 적용 개요\n",
    "1. **Convolution Layer**: 이미지의 특징을 추출하는 단계.\n",
    "2. **Activation Function**: 각 층의 출력에 비선형성을 추가하는 단계.\n",
    "3. **Pooling Layer**: 공간 크기를 줄여 계산 효율성을 높이는 단계.\n",
    "\n",
    "활성화 함수는 주로 Convolution Layer 다음에 적용되며, 이를 통해 신경망이 더 복잡한 특징을 학습할 수 있게 됩니다.\n",
    "\n",
    "### 주요 활성화 함수\n",
    "- **ReLU**: 가장 많이 사용되는 활성화 함수로, 음수를 0으로 변환하고 양수는 그대로 통과시킵니다.\n",
    "  - 공식: $ f(x) = \\max(0, x) $\n",
    "  \n",
    "- **Leaky ReLU**: ReLU의 변형으로, 음수 값을 완전히 제거하지 않고 작은 기울기를 유지하여 음의 입력에도 학습이 가능하도록 합니다.\n",
    "  - 공식: $ f(x) = \\max(0.01x, x) $\n",
    "  \n",
    "- **Sigmoid**: 출력값을 0과 1 사이로 제한하여 확률적 출력을 얻을 수 있습니다.\n",
    "  - 공식: $ f(x) = \\frac{1}{1 + e^{-x}} $\n",
    "\n",
    "- **Tanh**: 출력값을 -1과 1 사이로 제한합니다. Sigmoid보다 중심이 0에 가까워지는 특성을 가지고 있습니다.\n",
    "  - 공식: $ f(x) = \\tanh(x) $\n",
    "\n",
    "### CNN에서 활성화 함수 적용 예시 (PyTorch)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# CNN 모델 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional Layer (input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # Activation function ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 10)  # Assuming input image size is 28x28\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution -> Activation -> Pooling\n",
    "        x = self.conv1(x)          # Convolutional layer\n",
    "        x = self.relu(x)           # Apply ReLU activation function\n",
    "        x = self.pool(x)           # Max pooling layer\n",
    "        x = x.view(-1, 16 * 14 * 14)  # Flatten the output for fully connected layer\n",
    "        x = self.fc1(x)            # Fully connected layer\n",
    "        return x\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = SimpleCNN()\n",
    "\n",
    "# 입력 이미지 텐서 생성 (배치 크기: 1, 채널: 1, 이미지 크기: 28x28)\n",
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "# 모델에 입력을 통과시켜 출력 얻기\n",
    "output = model(input_tensor)\n",
    "print(output)\n",
    "```\n",
    "\n",
    "### 코드 설명\n",
    "1. **Convolution Layer (`nn.Conv2d`)**: 3x3 커널을 사용하여 특징을 추출합니다.\n",
    "2. **Activation Function (`nn.ReLU`)**: `conv1`의 출력에 ReLU 활성화 함수를 적용합니다.\n",
    "3. **Pooling Layer (`nn.MaxPool2d`)**: 2x2 크기의 풀링을 적용해 출력의 크기를 줄입니다.\n",
    "4. **Flattening**: Fully connected layer에 입력하기 위해 풀링된 출력을 1차원으로 펼칩니다.\n",
    "5. **Fully Connected Layer (`nn.Linear`)**: 마지막 단계에서 분류를 수행합니다.\n",
    "\n",
    "### 다른 활성화 함수 적용 방법\n",
    "ReLU 대신 다른 활성화 함수를 적용하려면 `self.relu` 부분을 원하는 함수로 변경하면 됩니다. 예를 들어 Leaky ReLU는 `nn.LeakyReLU()`로, Sigmoid는 `nn.Sigmoid()`로 쉽게 교체할 수 있습니다.\n",
    "\n",
    "```python\n",
    "self.leaky_relu = nn.LeakyReLU()  # Leaky ReLU\n",
    "self.sigmoid = nn.Sigmoid()       # Sigmoid\n",
    "```\n",
    "\n",
    "이 코드는 간단한 CNN 모델에서 활성화 함수를 적용하는 방법을 보여주며, 다양한 활성화 함수를 실험해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀링층(Pooling Layer)** 는 CNN(Convolutional Neural Network)에서 중요한 역할을 하는 층으로, 주로 **특징 맵의 공간적 차원을 줄이거나 중요한 정보를 요약** 하는 데 사용됩니다. 풀링층은 이미지나 데이터의 공간적인 크기를 축소하여 계산 효율성을 높이고, 과적합(overfitting)을 줄이는 데 기여합니다. 또한 위치에 무관한 중요한 패턴을 추출하는 데도 사용됩니다.\n",
    "\n",
    "### 풀링층의 작동 원리\n",
    "\n",
    "1. **입력 데이터의 차원 축소**\n",
    "   - 풀링층은 입력 이미지나 특징 맵에서 작은 영역(윈도우)을 선택해 그 영역에서 가장 중요한 값을 추출하거나 평균값을 계산하여 차원을 줄입니다.\n",
    "   - **핵심 목표** 는 중요한 정보만 남기고, 불필요한 세부 정보를 제거하여 신경망의 연산량을 줄이는 것입니다.\n",
    "\n",
    "2. **대표적인 풀링 기법**\n",
    "   - **Max Pooling**: 풀링 윈도우 내에서 **가장 큰 값** 을 선택합니다. 주로 엣지나 강한 특징을 강조합니다.\n",
    "   - **Average Pooling**: 풀링 윈도우 내의 **평균값** 을 선택합니다. 특징을 부드럽게 요약하는 데 사용됩니다.\n",
    "   - **Global Pooling**: 전체 맵에서 하나의 값(평균 혹은 최대값)을 뽑아 차원을 완전히 축소합니다. 주로 분류 층 직전에 사용됩니다.\n",
    "\n",
    "3. **스트라이드(Stride)**\n",
    "   - 풀링 연산에서 **스트라이드(stride)** 는 윈도우가 얼마나 많이 이동하는지를 결정합니다. 스트라이드가 크면 더 많은 차원 축소가 이루어집니다.\n",
    "\n",
    "4. **패딩(Padding)**\n",
    "   - 패딩은 경계 처리에 대한 옵션으로, 풀링 연산에서 데이터를 손실 없이 처리하기 위해 경계를 확장할 수 있습니다. 일반적으로 풀링 층에서는 패딩을 많이 사용하지 않지만, 경우에 따라 경계 정보를 보존하기 위해 적용될 수 있습니다.\n",
    "\n",
    "### 풀링 공식\n",
    "\n",
    "**Max Pooling** 과 **Average Pooling** 의 계산 공식은 간단합니다. 풀링 창 크기를 $ f \\times f $라 하고, 스트라이드를 $ s $라고 할 때, 입력 데이터의 크기 $ W \\times H $에서 출력 크기는 다음과 같이 계산됩니다:\n",
    "\n",
    "- 출력 너비: $ \\text{Output Width} = \\frac{W - f}{s} + 1 $\n",
    "- 출력 높이: $ \\text{Output Height} = \\frac{H - f}{s} + 1 $\n",
    "\n",
    "### 풀링층의 핵심 개념\n",
    "- **차원 축소**: 풀링을 통해 특징 맵의 크기를 줄이고, 계산량을 줄이며 과적합을 방지합니다.\n",
    "- **로컬 특성 요약**: 풀링은 입력 데이터의 작은 영역에서 중요한 값을 선택하여 더 작은 크기의 출력 맵을 생성합니다.\n",
    "- **특징 불변성**: 풀링은 입력 데이터의 작은 변화에 대해 불변성을 제공하며, 위치에 관계없이 중요한 특징을 유지합니다.\n",
    "\n",
    "### 코드 예시 (PyTorch)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 예시 데이터 (배치 크기: 1, 채널: 1, 크기: 4x4)\n",
    "input_tensor = torch.tensor([[[[1.0, 2.0, 3.0, 4.0],\n",
    "                               [5.0, 6.0, 7.0, 8.0],\n",
    "                               [9.0, 10.0, 11.0, 12.0],\n",
    "                               [13.0, 14.0, 15.0, 16.0]]]])\n",
    "\n",
    "# Max Pooling 적용 (2x2 풀링 창, 스트라이드 2)\n",
    "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "max_pooled_output = max_pool(input_tensor)\n",
    "\n",
    "# Average Pooling 적용 (2x2 풀링 창, 스트라이드 2)\n",
    "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "avg_pooled_output = avg_pool(input_tensor)\n",
    "\n",
    "print(\"Max Pooling 결과:\")\n",
    "print(max_pooled_output)\n",
    "\n",
    "print(\"\\nAverage Pooling 결과:\")\n",
    "print(avg_pooled_output)\n",
    "```\n",
    "\n",
    "### 코드 설명\n",
    "1. **입력 텐서** 는 크기 $4 \\times 4$인 2D 텐서로, 예시로 1개의 채널을 가진 데이터를 만듭니다.\n",
    "2. **Max Pooling**:\n",
    "   - `nn.MaxPool2d(kernel_size=2, stride=2)`을 사용하여 $2 \\times 2$ 크기의 윈도우로 최대값을 추출합니다.\n",
    "   - `stride=2`로 설정하여 풀링 윈도우가 두 칸씩 이동하면서 입력 데이터를 축소합니다.\n",
    "   - 출력 크기는 $2 \\times 2$로 줄어듭니다.\n",
    "   \n",
    "3. **Average Pooling**:\n",
    "   - `nn.AvgPool2d(kernel_size=2, stride=2)`을 사용하여 $2 \\times 2$ 크기의 윈도우로 평균값을 계산합니다.\n",
    "   - 동일하게 $2 \\times 2$ 크기로 출력이 줄어듭니다.\n",
    "\n",
    "### 출력 결과\n",
    "```\n",
    "Max Pooling 결과:\n",
    "tensor([[[[ 6.,  8.],\n",
    "          [14., 16.]]]])\n",
    "\n",
    "Average Pooling 결과:\n",
    "tensor([[[[ 3.5,  5.5],\n",
    "          [11.5, 13.5]]]])\n",
    "```\n",
    "\n",
    "### 요약\n",
    "- **Max Pooling** 은 각 윈도우 내에서 **최대값** 을 선택하고, **Average Pooling** 은 윈도우 내의 **평균값** 을 계산합니다.\n",
    "- 풀링층은 특징을 요약하고 차원을 줄이며, 계산 효율성을 높이고 모델의 **과적합을 방지** 하는 중요한 역할을 합니다.\n",
    "- PyTorch에서 쉽게 풀링 연산을 적용할 수 있으며, CNN에서 필수적으로 사용되는 요소입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Pooling** 은 가중치나 편향이 없다. 그냥 최대값을 추출하면 돼서 불필요하다.  \n",
    "**Average Pooling** 은 풀링 커널의 크기를 분모로 가지는 가중치가 있다. 평균을 계산해야 하기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링 커널은 입력 텐서가 여러 개여도 하나만 써도 되서 그냥 그렇게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted-Window(kernel, filter)** 를 사용하는 풀링도 있다. 합성곱 커널과 같은 기능을 하지만 풀링 커널이기 때문에 모든 슬라이스에 같은 걸 사용한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
